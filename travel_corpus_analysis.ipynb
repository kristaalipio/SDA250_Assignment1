{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556daa96-1275-4da8-ad7a-6b997edd5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2019f4da-7458-4c04-b6e6-dec2a5b8b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the recipe corpus from the data directory\n",
    "corpus_root = \"./data\"\n",
    "reviews = PlaintextCorpusReader(corpus_root, '.*')\n",
    "travel_corpus = reviews.words('travelblog.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0087f8-f41c-4166-9471-cb62662e82b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24f306-d6a8-49a3-b734-2b0a15791882",
   "metadata": {},
   "source": [
    "# 1. length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "187554a9-8406-46a5-9cb3-a24556cf32a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus length: 9922\n",
      "Alphabet-only and lower-cased corpus length: 8515\n"
     ]
    }
   ],
   "source": [
    "## Calculate the length of the original recipe corpus\n",
    "travel_corpus_len = len(travel_corpus)\n",
    "print(f\"Original corpus length: {travel_corpus_len}\")\n",
    "\n",
    "## Create a corpus containing only alphabetic words and convert them to lowercase\n",
    "travel_alpha_corpus = [word.lower() for word in travel_corpus if word.isalpha()]\n",
    "travel_alpha_corpus_len = len(travel_alpha_corpus)\n",
    "print(f\"Alphabet-only and lower-cased corpus length: {travel_alpha_corpus_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cb302-3f1b-4d0f-a60e-1f773d684d6d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. lexical diversity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b0412e-6ef0-4dea-a973-8f50e89746d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for calculating the lexical diversity of a text\n",
    "def lexical_diversity(text):\n",
    "    sorted_words = sorted(w.lower() for w in text)\n",
    "    unique_sorted_words = sorted(set(w.lower() for w in text))\n",
    "    return len(set(unique_sorted_words)) / len(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e664b1-8586-4316-bf7e-1e9677612d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexical diversity for the travel corpus: 0.19018343075992744\n",
      "lexical diversity for the alphabet only recipe corpus: 0.21397533763945978\n"
     ]
    }
   ],
   "source": [
    "## Print the lexical diversities\n",
    "print(f\"lexical diversity for the travel corpus: {lexical_diversity(travel_corpus)}\")\n",
    "print(f\"lexical diversity for the alphabet only recipe corpus: {lexical_diversity(travel_alpha_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bf3f4-d9fb-4d3c-b6e3-96c8e48ee9d8",
   "metadata": {},
   "source": [
    "# 3. top 10 most frequent words + their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9803f5-9c35-4081-a0fb-5781cb1fdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the frequency distributions for the alphabet-only recipe corpus\n",
    "freq_dist = FreqDist(travel_alpha_corpus)\n",
    "\n",
    "## Store the 10 most frequent words from each frequency distribution\n",
    "most_freq_words = freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94878c51-db69-46bc-b421-52b63103a7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent words in the alphabet-only travel corpus:\n",
      "word: 'to', count: 293\n",
      "word: 'the', count: 286\n",
      "word: 'you', count: 258\n",
      "word: 'and', count: 223\n",
      "word: 'i', count: 208\n",
      "word: 'a', count: 205\n",
      "word: 'in', count: 183\n",
      "word: 'of', count: 155\n",
      "word: 'your', count: 143\n",
      "word: 'that', count: 113\n"
     ]
    }
   ],
   "source": [
    "## Print the 10 most frequent words\n",
    "print(\"10 most frequent words in the alphabet-only travel corpus:\")\n",
    "for word, count in most_freq_words:\n",
    "    print(f\"word: '{word}', count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ea253-2d77-4bb9-9c05-3f57420a9e71",
   "metadata": {},
   "source": [
    "# 4. words with atleast 10 characters long + their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8050398c-b339-4304-8b67-cc7bb30adfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that are at least 10 characters long in the alphabet-only travel corpus:\n",
      "word: 'shipwrecked', count: 2\n",
      "word: 'antarctica', count: 1\n",
      "word: 'lookalikes', count: 1\n",
      "word: 'originally', count: 1\n",
      "word: 'establishing', count: 1\n",
      "word: 'continents', count: 1\n",
      "word: 'developing', count: 2\n",
      "word: 'conventional', count: 1\n",
      "word: 'influential', count: 1\n",
      "word: 'everything', count: 6\n",
      "word: 'businesses', count: 1\n",
      "word: 'opportunity', count: 2\n",
      "word: 'consulting', count: 1\n",
      "word: 'honeymoons', count: 1\n",
      "word: 'preparation', count: 3\n",
      "word: 'independently', count: 3\n",
      "word: 'consolidate', count: 1\n",
      "word: 'environment', count: 1\n",
      "word: 'fearmongering', count: 1\n",
      "word: 'destination', count: 18\n",
      "word: 'everywhere', count: 2\n",
      "word: 'frequently', count: 2\n",
      "word: 'extensions', count: 1\n",
      "word: 'possibilities', count: 1\n",
      "word: 'independent', count: 2\n",
      "word: 'philosophy', count: 1\n",
      "word: 'environmentally', count: 1\n",
      "word: 'economically', count: 1\n",
      "word: 'responsible', count: 2\n",
      "word: 'offsetting', count: 1\n",
      "word: 'photographing', count: 1\n",
      "word: 'understanding', count: 1\n",
      "word: 'historical', count: 1\n",
      "word: 'overtourism', count: 1\n",
      "word: 'destinations', count: 3\n",
      "word: 'struggling', count: 1\n",
      "word: 'appreciate', count: 2\n",
      "word: 'difference', count: 1\n",
      "word: 'tantamount', count: 1\n",
      "word: 'government', count: 6\n",
      "word: 'emphatically', count: 1\n",
      "word: 'invitation', count: 1\n",
      "word: 'grandfather', count: 1\n",
      "word: 'progressive', count: 1\n",
      "word: 'healthcare', count: 1\n",
      "word: 'celebration', count: 1\n",
      "word: 'constantly', count: 3\n",
      "word: 'definition', count: 1\n",
      "word: 'guesthouse', count: 4\n",
      "word: 'occasionally', count: 1\n",
      "word: 'uncomfortable', count: 1\n",
      "word: 'relationship', count: 6\n",
      "word: 'understand', count: 4\n",
      "word: 'accommodation', count: 4\n",
      "word: 'inspirational', count: 1\n",
      "word: 'confidence', count: 4\n",
      "word: 'interesting', count: 1\n",
      "word: 'absolutely', count: 3\n",
      "word: 'backpacking', count: 2\n",
      "word: 'prioritized', count: 1\n",
      "word: 'revolutionary', count: 1\n",
      "word: 'pickpocketed', count: 2\n",
      "word: 'beforehand', count: 3\n",
      "word: 'financially', count: 3\n",
      "word: 'precautions', count: 1\n",
      "word: 'documented', count: 2\n",
      "word: 'thoroughly', count: 2\n",
      "word: 'researching', count: 2\n",
      "word: 'information', count: 4\n",
      "word: 'transportation', count: 3\n",
      "word: 'vaccinations', count: 1\n",
      "word: 'prescriptions', count: 1\n",
      "word: 'activities', count: 2\n",
      "word: 'especially', count: 9\n",
      "word: 'enormously', count: 1\n",
      "word: 'despondent', count: 1\n",
      "word: 'certificate', count: 1\n",
      "word: 'technology', count: 2\n",
      "word: 'unfathomable', count: 1\n",
      "word: 'smartphone', count: 2\n",
      "word: 'definitely', count: 1\n",
      "word: 'medication', count: 1\n",
      "word: 'photography', count: 1\n",
      "word: 'equivalent', count: 1\n",
      "word: 'transferwise', count: 1\n",
      "word: 'guesthouses', count: 1\n",
      "word: 'slashproof', count: 1\n",
      "word: 'professional', count: 2\n",
      "word: 'determined', count: 1\n",
      "word: 'opportunistic', count: 1\n",
      "word: 'accessible', count: 1\n",
      "word: 'friendships', count: 1\n",
      "word: 'befriending', count: 1\n",
      "word: 'unattended', count: 1\n",
      "word: 'outrageously', count: 1\n",
      "word: 'electronics', count: 2\n",
      "word: 'applicable', count: 1\n",
      "word: 'vulnerable', count: 2\n",
      "word: 'altogether', count: 1\n",
      "word: 'importantly', count: 2\n",
      "word: 'companions', count: 1\n",
      "word: 'pickpocket', count: 1\n",
      "word: 'birkenstocks', count: 1\n",
      "word: 'sweatshirt', count: 1\n",
      "word: 'university', count: 1\n",
      "word: 'unfamiliar', count: 1\n",
      "word: 'impossible', count: 1\n",
      "word: 'backpacker', count: 1\n",
      "word: 'appearance', count: 1\n",
      "word: 'harassment', count: 1\n",
      "word: 'continuing', count: 1\n",
      "word: 'shoestring', count: 1\n",
      "word: 'comfortable', count: 3\n",
      "word: 'neighborhood', count: 3\n",
      "word: 'residential', count: 1\n",
      "word: 'reputation', count: 1\n",
      "word: 'tripadvisor', count: 1\n",
      "word: 'situations', count: 1\n",
      "word: 'applicator', count: 1\n",
      "word: 'prospective', count: 1\n",
      "word: 'particular', count: 3\n",
      "word: 'personally', count: 1\n",
      "word: 'designated', count: 1\n",
      "word: 'consistent', count: 1\n",
      "word: 'whereabouts', count: 1\n",
      "word: 'protesting', count: 1\n",
      "word: 'ridiculous', count: 1\n",
      "word: 'inaccurate', count: 1\n",
      "word: 'incomplete', count: 1\n",
      "word: 'discussing', count: 1\n",
      "word: 'knowledgeable', count: 1\n",
      "word: 'kidnapping', count: 1\n",
      "word: 'international', count: 1\n",
      "word: 'insurgency', count: 1\n",
      "word: 'philippines', count: 5\n",
      "word: 'incredibly', count: 1\n",
      "word: 'department', count: 2\n",
      "word: 'organizations', count: 1\n",
      "word: 'archipelago', count: 2\n",
      "word: 'completely', count: 5\n",
      "word: 'surrounding', count: 2\n",
      "word: 'whatsoever', count: 1\n",
      "word: 'conditions', count: 1\n",
      "word: 'dominating', count: 1\n",
      "word: 'assumptions', count: 1\n",
      "word: 'recommendation', count: 2\n",
      "word: 'experienced', count: 1\n",
      "word: 'couchsurfing', count: 3\n",
      "word: 'suggestion', count: 1\n",
      "word: 'alternatively', count: 1\n",
      "word: 'communication', count: 6\n",
      "word: 'extensively', count: 1\n",
      "word: 'familiarize', count: 1\n",
      "word: 'prevalence', count: 1\n",
      "word: 'influences', count: 1\n",
      "word: 'successfully', count: 1\n",
      "word: 'reassurance', count: 1\n",
      "word: 'protecting', count: 1\n",
      "word: 'communicate', count: 2\n",
      "word: 'dispatches', count: 1\n",
      "word: 'experience', count: 1\n",
      "word: 'themselves', count: 1\n",
      "word: 'relationships', count: 1\n",
      "word: 'salvageable', count: 1\n",
      "word: 'exceptionally', count: 1\n",
      "word: 'phenomenal', count: 1\n",
      "word: 'permission', count: 1\n",
      "word: 'simultaneous', count: 1\n",
      "word: 'accidentally', count: 1\n",
      "word: 'audiobooks', count: 1\n",
      "word: 'motivation', count: 1\n",
      "word: 'indirectly', count: 1\n",
      "word: 'meticulously', count: 1\n",
      "word: 'intellectually', count: 1\n",
      "word: 'immigration', count: 1\n",
      "word: 'directions', count: 1\n",
      "word: 'reassuring', count: 1\n",
      "word: 'adventurous', count: 2\n",
      "word: 'overwhelmingly', count: 1\n",
      "word: 'considering', count: 1\n",
      "word: 'occasional', count: 1\n",
      "word: 'conference', count: 1\n",
      "word: 'complicated', count: 3\n",
      "word: 'contribute', count: 1\n",
      "word: 'fortunately', count: 1\n",
      "word: 'hypnotized', count: 1\n",
      "word: 'nonrefundable', count: 1\n",
      "word: 'overwhelmed', count: 1\n",
      "word: 'fundraising', count: 1\n",
      "word: 'organizing', count: 1\n",
      "word: 'overwhelming', count: 1\n",
      "word: 'temperature', count: 1\n"
     ]
    }
   ],
   "source": [
    "## Store the words and their counts that are at least 10 characters long\n",
    "long_words_with_counts = [(word, count) for word, count in freq_dist.items() if len(word) >= 10]\n",
    "\n",
    "## Print the words that are at least 10 characters long and their counts\n",
    "print(\"Words that are at least 10 characters long in the alphabet-only travel corpus:\")\n",
    "for word, count in long_words_with_counts:\n",
    "    print(f\"word: '{word}', count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6ae61-4e3e-402a-afb9-daca00c56451",
   "metadata": {},
   "source": [
    "# 5. the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4efcf8c1-622d-4590-88d6-80dcfe48719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sentence:\n",
      "Check in Regularly It ’ s a good idea for at least one designated friend or family member to have a copy of your itinerary in advance : your flight numbers , your accommodation , and a general schedule of where you ’ ll be on which dates , as well as information on your travel insurance , credit cards , and a bank account number .\n",
      "\n",
      "number of words: 67\n"
     ]
    }
   ],
   "source": [
    "## Retrieve the sentences from the recipe corpus\n",
    "recipe_sentences = reviews.sents('travelblog.txt')\n",
    "\n",
    "## Find the longest sentence\n",
    "longest_sentence = []\n",
    "for sentence in recipe_sentences:\n",
    "    if len(longest_sentence) < len(sentence):\n",
    "        longest_sentence = sentence \n",
    "\n",
    "## Join the words of the longest sentence into a single string for printing\n",
    "joined_longest_sentence = ' '.join(longest_sentence)\n",
    "\n",
    "## Print the longest sentence along with the word count\n",
    "print(f\"longest sentence:\\n{joined_longest_sentence}\")\n",
    "print()\n",
    "print(f\"number of words: {len(longest_sentence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879f9c9-19e7-429f-88da-30db20d64c62",
   "metadata": {},
   "source": [
    "# 6. stemmed version of longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb3b2e4-0fb1-47dd-83d2-fdfcce4d2030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter stemmed longest sentence:\n",
      "check in regularli it ’ s a good idea for at least one design friend or famili member to have a copi of your itinerari in advanc : your flight number , your accommod , and a gener schedul of where you ’ ll be on which date , as well as inform on your travel insur , credit card , and a bank account number .\n",
      "\n",
      "lancaster stemmed longest sentence:\n",
      "check in regul it ’ s a good ide for at least on design friend or famy memb to hav a cop of yo itin in adv : yo flight numb , yo accommod , and a gen schedule of wher you ’ ll be on which dat , as wel as inform on yo travel ins , credit card , and a bank account numb .\n"
     ]
    }
   ],
   "source": [
    "## Initialize the stemmers\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "## Stem the words of the longest sentence using both stemmers\n",
    "port_stemmed_sentence = []\n",
    "lanc_stemmed_sentence = []\n",
    "for word in longest_sentence:\n",
    "    port_stemmed_sentence.append(porter_stemmer.stem(word))\n",
    "    lanc_stemmed_sentence.append(lancaster_stemmer.stem(word))\n",
    "\n",
    "## Join the stemmed words into single strings for printing\n",
    "joined_port_stemmed_sentence = ' '.join(port_stemmed_sentence)\n",
    "joined_lanc_stemmed_sentence = ' '.join(lanc_stemmed_sentence)\n",
    "\n",
    "## Print the both stemmed longest sentences\n",
    "print(f\"porter stemmed longest sentence:\\n{joined_port_stemmed_sentence}\")\n",
    "print()\n",
    "print(f\"lancaster stemmed longest sentence:\\n{joined_lanc_stemmed_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae850d5-9302-4155-9601-b23fe87272a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
